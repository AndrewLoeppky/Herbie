{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Brian Blaylock**  \n",
    "**June 26, 2020**  \n",
    "\n",
    "üåê HRRR Archive Website: http://hrrr.chpc.utah.edu/  \n",
    "üöë Support: atmos-mesowest@lists.utah.edu  \n",
    "üìß Brian Blaylock: blaylockbk@gmail.com  \n",
    "‚úí Citation this details:\n",
    "> Blaylock B., J. Horel and S. Liston, 2017: Cloud Archiving and Data Mining of High Resolution Rapid Refresh Model Output. Computers and Geosciences. 109, 43-50. https://doi.org/10.1016/j.cageo.2017.08.005\n",
    "\n",
    "---\n",
    "\n",
    "# üèó HRRR Download Demo: Part 3\n",
    "## A modified function to download many full files or subsets of files\n",
    "\n",
    "- [Part 1: How to download a bunch of HRRR grib2 files (full file)](./demo_download_hrrr_archive_part1.ipynb)\n",
    "- [Part 2: How to download a subset of variables from a HRRR file](./demo_download_hrrr_archive_part2.ipynb)\n",
    "- [Part 3: A function that can download many full files, or subset of files](./demo_download_hrrr_archive_part3.ipynb)\n",
    "- [Part 4: Opening GRIB2 files in Python with xarray and cfgrib](./demo_download_hrrr_archive_part4.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "This notebook combines what we learned in **Part 1** and **Part 2** to download many HRRR files based on datetime and forecast *and* download a select amount of GRIB fields (not the full file).\n",
    "\n",
    "The main change is in the `download_HRRR` function, that now accepts a \"searchString\" argument where we define our **searchString** for the variables we want to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import urllib.request  # Used to download the file\n",
    "import requests        # Used to check if a URL exists\n",
    "import warnings\n",
    "import pandas as pd    # Just used for the date_range function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reporthook(a, b, c):\n",
    "    \"\"\"\n",
    "    Report download progress in megabytes (prints progress to screen).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    a : Chunk number\n",
    "    b : Maximum chunk size\n",
    "    c : Total size of the download\n",
    "    \"\"\"\n",
    "    chunk_progress = a * b / c * 100\n",
    "    total_size_MB =  c / 1000000.\n",
    "    print(f\"\\r Download Progress: {chunk_progress:.2f}% of {total_size_MB:.1f} MB\\r\", end='')\n",
    "\n",
    "def download_HRRR_subset(url, searchString, SAVEDIR='./', dryrun=False):\n",
    "    \"\"\"\n",
    "    Download a subset of GRIB fields from a HRRR file.\n",
    "    \n",
    "    This assumes there is an index (.idx) file available for the file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : string\n",
    "        The URL for the HRRR file you are trying to download. There must be an \n",
    "        index file for the GRIB2 file. For example, if \n",
    "        ``url='https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2'``,\n",
    "        then ``https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2.idx``\n",
    "        must also exist on the server.\n",
    "    searchString : str\n",
    "        The string you are looking for in each line of the index file. \n",
    "        Take a look at the \n",
    "        .idx file at https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2.idx\n",
    "        to get familiar with what is in each line.\n",
    "        Also look at this webpage: http://hrrr.chpc.utah.edu/HRRR_archive/hrrr_sfc_table_f00-f01.html\n",
    "        for additional details.**You should focus on the variable and level \n",
    "        field for your searches**.\n",
    "        \n",
    "        You may use regular expression syntax to customize your search. \n",
    "        Check out this regulare expression cheatsheet:\n",
    "        https://link.medium.com/7rxduD2e06\n",
    "        \n",
    "        Here are a few examples that can help you get started\n",
    "        \n",
    "        ================ ===============================================\n",
    "        ``searchString`` Messages that will be downloaded\n",
    "        ================ ===============================================\n",
    "        ':TMP:2 m'       Temperature at 2 m.\n",
    "        ':TMP:'          Temperature fields at all levels.\n",
    "        ':500 mb:'       All variables on the 500 mb level.\n",
    "        ':APCP:'         All accumulated precipitation fields.\n",
    "        ':UGRD:10 m:'    U wind component at 10 meters.\n",
    "        ':(U|V)GRD:'     U and V wind component at all levels.\n",
    "        ':.GRD:'         (Same as above)\n",
    "        ':(TMP|DPT):'    Temperature and Dew Point for all levels .\n",
    "        ':(TMP|DPT|RH):' TMP, DPT, and Relative Humidity for all levels.\n",
    "        ':REFC:'         Composite Reflectivity\n",
    "        ':surface:'      All variables at the surface.\n",
    "        ================ ===============================================    \n",
    "        \n",
    "    SAVEDIR : string\n",
    "        Directory path to save the file, default is the current directory.\n",
    "    dryrun : bool\n",
    "        If True, do not actually download, but print out what the function will\n",
    "        attempt to do.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The path and name of the new file.\n",
    "    \"\"\"\n",
    "    # Ping Pando first. This *might* prevent a \"bad handshake\" error.\n",
    "    if 'pando' in url:\n",
    "        try:\n",
    "            requests.head('https://pando-rgw01.chpc.utah.edu/')\n",
    "        except:\n",
    "            print('bad handshake...am I able to on?')\n",
    "            pass\n",
    "    \n",
    "    # Make SAVEDIR if path doesn't exist\n",
    "    if not os.path.exists(SAVEDIR):\n",
    "        os.makedirs(SAVEDIR)\n",
    "        print(f'Created directory: {SAVEDIR}')\n",
    "\n",
    "    \n",
    "    # Make a request for the .idx file for the above URL\n",
    "    idx = url + '.idx'\n",
    "    r = requests.get(idx)\n",
    "\n",
    "    # Check that the file exists. If there isn't an index, you will get a 404 error.\n",
    "    if not r.ok: \n",
    "        print('‚ùå SORRY! Status Code:', r.status_code, r.reason)\n",
    "        print(f'‚ùå It does not look like the index file exists: {idx}')\n",
    "\n",
    "    # Read the text lines of the request\n",
    "    lines = r.text.split('\\n')\n",
    "    \n",
    "    # Search expression\n",
    "    expr = re.compile(searchString)\n",
    "\n",
    "    # Store the byte ranges in a dictionary\n",
    "    #     {byte-range-as-string: line}\n",
    "    byte_ranges = {}\n",
    "    for n, line in enumerate(lines, start=1):\n",
    "        # n is the line number (starting from 1) so that when we call for \n",
    "        # `lines[n]` it will give us the next line. (Clear as mud??)\n",
    "\n",
    "        # Use the compiled regular expression to search the line\n",
    "        if expr.search(line):   \n",
    "            # aka, if the line contains the string we are looking for...\n",
    "\n",
    "            # Get the beginning byte in the line we found\n",
    "            parts = line.split(':')\n",
    "            rangestart = int(parts[1])\n",
    "\n",
    "            # Get the beginning byte in the next line...\n",
    "            if n+1 < len(lines):\n",
    "                # ...if there is a next line\n",
    "                parts = lines[n].split(':')\n",
    "                rangeend = int(parts[1])\n",
    "            else:\n",
    "                # ...if there isn't a next line, then go to the end of the file.\n",
    "                rangeend = ''\n",
    "\n",
    "            # Store the byte-range string in our dictionary, \n",
    "            # and keep the line information too so we can refer back to it.\n",
    "            byte_ranges[f'{rangestart}-{rangeend}'] = line\n",
    "    \n",
    "    # What should we name the file we save this data to?\n",
    "    # Let's name it something like `subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
    "    runDate = list(byte_ranges.items())[0][1].split(':')[2][2:-2]\n",
    "    outFile = '_'.join(['subset', runDate, url.split('/')[-1]])\n",
    "    outFile = os.path.join(SAVEDIR, outFile)\n",
    "    \n",
    "    for i, (byteRange, line) in enumerate(byte_ranges.items()):\n",
    "        \n",
    "        if i == 0:\n",
    "            # If we are working on the first item, overwrite the existing file.\n",
    "            curl = f'curl -s --range {byteRange} {url} > {outFile}'\n",
    "        else:\n",
    "            # If we are working on not the first item, append the existing file.\n",
    "            curl = f'curl -s --range {byteRange} {url} >> {outFile}'\n",
    "            \n",
    "        num, byte, date, var, level, forecast, _ = line.split(':')\n",
    "        \n",
    "        if dryrun:\n",
    "            print(f'    üê´ Dry Run: Found GRIB line [{num:>3}]: variable={var}, level={level}, forecast={forecast}')\n",
    "            #print(f'    üê´ Dry Run: `{curl}`')\n",
    "        else:\n",
    "            print(f'  Downloading GRIB line [{num:>3}]: variable={var}, level={level}, forecast={forecast}')    \n",
    "            os.system(curl)\n",
    "    \n",
    "    if dryrun:\n",
    "        print(f'üåµ Dry Run: Success! Searched for [{searchString}] and found [{len(byte_ranges)}] GRIB fields. Would save as {outFile}')\n",
    "    else:\n",
    "        print(f'‚úÖ Success! Searched for [{searchString}] and got [{len(byte_ranges)}] GRIB fields and saved as {outFile}')\n",
    "    \n",
    "        return outFile\n",
    "    \n",
    "def download_HRRR(DATES, fxx=range(0, 1), searchString=None, model='hrrr',\n",
    "                  field='sfc', SOURCE='pando', SAVEDIR='./',\n",
    "                  dryrun=False):\n",
    "    \"\"\"\n",
    "    Downloads full HRRR grib2 files for a list of dates and forecasts.\n",
    "    \n",
    "    Files are downloaded from the University of Utah HRRR archive (Pando) \n",
    "    or NOAA Operational Model Archive and Distribution System (NOMADS).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    DATES : datetime or list of datetimes\n",
    "        A datetime or list of datetimes that represent the model \n",
    "        initialization time for which you want to download.\n",
    "    fxx : int or list of ints\n",
    "        Forecast lead time or list of forecast lead times to download.\n",
    "        Default only grabs analysis hour (f00), but you might want all\n",
    "        the forecasts hours, in that case, you could set ``fxx=range(0,19)``.\n",
    "    searchString : str\n",
    "        The string that describes the variables you want to download\n",
    "        from the file. This is used as the `searchString` in\n",
    "        ``download_hrrr_subset`` to looking for sepecific byte ranges\n",
    "        from the file to download. \n",
    "        \n",
    "        Default is None, meaning to not search for variables, but to\n",
    "        download the full file. ':' is an alias for None, becuase\n",
    "        it is equivalent to identifying every line in the .idx file.\n",
    "        Read the details below for more help on defining a suitable \n",
    "        ``searchString``.\n",
    "        \n",
    "        Take a look at the .idx file at \n",
    "        https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2.idx\n",
    "        to get familiar with what an index file is.\n",
    "        Also look at this webpage: http://hrrr.chpc.utah.edu/HRRR_archive/hrrr_sfc_table_f00-f01.html\n",
    "        for additional details.**You should focus on the variable and level \n",
    "        field for your searches**.\n",
    "        \n",
    "        You may use regular expression syntax to customize your search. \n",
    "        Check out this regulare expression cheatsheet:\n",
    "        https://link.medium.com/7rxduD2e06\n",
    "        \n",
    "        Here are a few examples that can help you get started\n",
    "        \n",
    "        ================ ===============================================\n",
    "        ``searchString`` Messages that will be downloaded\n",
    "        ================ ===============================================\n",
    "        ':TMP:2 m'       Temperature at 2 m.\n",
    "        ':TMP:'          Temperature fields at all levels.\n",
    "        ':500 mb:'       All variables on the 500 mb level.\n",
    "        ':APCP:'         All accumulated precipitation fields.\n",
    "        ':UGRD:10 m:'    U wind component at 10 meters.\n",
    "        ':(U|V)GRD:'     U and V wind component at all levels.\n",
    "        ':.GRD:'         (Same as above)\n",
    "        ':(TMP|DPT):'    Temperature and Dew Point for all levels .\n",
    "        ':(TMP|DPT|RH):' TMP, DPT, and Relative Humidity for all levels.\n",
    "        ':REFC:'         Composite Reflectivity\n",
    "        ':surface:'      All variables at the surface.\n",
    "        ================ =============================================== \n",
    "    model : {'hrrr', 'hrrrak', 'hrrrX'}\n",
    "        The model type you want to download.\n",
    "        - 'hrrr' HRRR Contiguous United States (operational)\n",
    "        - 'hrrrak' HRRR Alaska. You can also use 'alaska' as an alias.\n",
    "        - 'hrrrX' HRRR *experimental*\n",
    "    field : {'prs', 'sfc', 'nat', 'subh'}\n",
    "        Variable fields you wish to download. \n",
    "        - 'sfc' surface fields\n",
    "        - 'prs' pressure fields\n",
    "        - 'nat' native fields      ('nat' files are not available on Pando)\n",
    "        - 'subh' subhourly fields  ('subh' files are not available on Pando)\n",
    "    SOURCE : {'pando', 'nomads'}\n",
    "        Specify the source from which to download the HRRR files.\n",
    "        - 'pando' downloads HRRR files from University of Utah archive:\n",
    "        http://hrrr.chpc.utah.edu/        \n",
    "        - 'nomads' downloads HRRR files from NCEP NOMADS server:\n",
    "        https://nomads.ncep.noaa.gov/pub/data/nccf/com/hrrr/prod/\n",
    "    SAVEDIR : str\n",
    "        Directory path to save the downloaded HRRR files.\n",
    "    dryrun : bool\n",
    "        If True, instead of downloading the files, it will print out the\n",
    "        files that could be downloaded. This is set to False by default.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Downloads the HRRR files, with filename prepended with the run date\n",
    "    (i.e. `20170101_hrrr.t00z.wrfsfcf00.grib2`)\n",
    "    \"\"\"\n",
    "    \n",
    "    #**************************************************************************\n",
    "    ## Check function input\n",
    "    #**************************************************************************\n",
    "    \n",
    "    # Ping Pando first. This *might* prevent a \"bad handshake\" error.\n",
    "    if SOURCE == 'pando':\n",
    "        try:\n",
    "            requests.head('https://pando-rgw01.chpc.utah.edu/')\n",
    "        except:\n",
    "            print('bad handshake...am I able to on?')\n",
    "            pass\n",
    "    \n",
    "    # Force the `SOURCE` and `field` input string to be lower case.\n",
    "    SOURCE = SOURCE.lower()\n",
    "    field = field.lower()\n",
    "\n",
    "    # `DATES` and `fxx` should be a list-like object, but if it doesn't have\n",
    "    # length, (like if the user requests a single date or forecast hour),\n",
    "    # then turn it item into a list-like object.\n",
    "    if not hasattr(DATES, '__len__'): DATES = np.array([DATES])\n",
    "    if not hasattr(fxx, '__len__'): fxx = [fxx]\n",
    "    \n",
    "    # HRRR data on NOMADS is only available for today's and yesterday's runs.\n",
    "    # If any of the DATES are older than yesterday, raise a warning and\n",
    "    # change SOURCE to pando.\n",
    "    if SOURCE == 'nomads':\n",
    "        yesterday = datetime.utcnow() - timedelta(days=1)\n",
    "        yesterday = datetime(yesterday.year, yesterday.month, yesterday.day)\n",
    "        if any(DATES < yesterday):\n",
    "            warnings.warn(\"Changed the SOURCE to 'pando' because one or more of the requested DATES are for more than two days ago.\")\n",
    "            SOURCE = 'pando'\n",
    "    \n",
    "    # The user may set `model='alaska'` as an alias for 'hrrrak'.\n",
    "    if model.lower() == 'alaska': model = 'hrrrak'\n",
    "      \n",
    "    _SOURCE = {'pando', 'nomads'}\n",
    "    assert SOURCE in _SOURCE, f'`SOURCE` must be one of {_SOURCE}'\n",
    "    \n",
    "    # The model type and field depends on the SOURCE the files are downloaded.\n",
    "    if SOURCE == 'pando':\n",
    "        _models = {'hrrr', 'hrrrak', 'hrrrX'}\n",
    "        _fields = {'sfc', 'prs'}\n",
    "    elif SOURCE == 'nomads':\n",
    "        _models = {'hrrr', 'hrrrak'}\n",
    "        _fields = {'sfc', 'prs', 'nat', 'subh'}\n",
    "        \n",
    "    assert model in _models, f'`model` should be set to one of {_models} for `SOURCE={SOURCE}`'\n",
    "    assert field in _fields, f'`field` should be set to one of {_fields} for `SOURCE={SOURCE}`'\n",
    "    \n",
    "    # Make SAVEDIR if path doesn't exist\n",
    "    if not os.path.exists(SAVEDIR):\n",
    "        os.makedirs(SAVEDIR)\n",
    "        print(f'Created directory: {SAVEDIR}')\n",
    "\n",
    "    #**************************************************************************\n",
    "    # Build the URL path for every file we want\n",
    "    #**************************************************************************\n",
    "    # An example URL for a file from Pando is \n",
    "    # https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2\n",
    "    # \n",
    "    # An example URL for a file from NOMADS is\n",
    "    # https://nomads.ncep.noaa.gov/pub/data/nccf/com/hrrr/prod/hrrr.20200624/conus/hrrr.t00z.wrfsfcf09.grib2\n",
    "        \n",
    "    if SOURCE == 'pando':\n",
    "        base = f'https://pando-rgw01.chpc.utah.edu/{model}/{field}'\n",
    "        URL_list = [f'{base}/{DATE:%Y%m%d}/{model}.t{DATE:%H}z.wrf{field}f{f:02d}.grib2' for DATE in DATES for f in fxx]\n",
    "    \n",
    "    elif SOURCE == 'nomads':\n",
    "        base = 'https://nomads.ncep.noaa.gov/pub/data/nccf/com/hrrr/prod'\n",
    "        if model == 'hrrr':\n",
    "            URL_list = [f'{base}/hrrr.{DATE:%Y%m%d}/conus/hrrr.t{DATE:%H}z.wrf{field}f{f:02d}.grib2' for DATE in DATES for f in fxx]\n",
    "        elif model == 'hrrrak':\n",
    "            URL_list = [f'{base}/hrrr.{DATE:%Y%m%d}/alaska/hrrr.t{DATE:%H}z.wrf{field}f{f:02d}.ak.grib2' for DATE in DATES for f in fxx]\n",
    "    \n",
    "    #**************************************************************************\n",
    "    # Ok, so we have a URL and filename for each requested forecast hour.\n",
    "    # Now we need to check if each of those files exist, and if it does,\n",
    "    # we will download that file to the SAVEDIR location.\n",
    "    \n",
    "    if dryrun:\n",
    "        print(f'üåµ Info: Dry Run {len(URL_list)} GRIB2 files')\n",
    "    else:\n",
    "        print(f'üí° Info: Downloading {len(URL_list)} GRIB2 files')\n",
    "    \n",
    "    for file_URL in URL_list:\n",
    "        # We want to prepend the filename with the run date, YYYYMMDD\n",
    "        if SOURCE == 'pando':\n",
    "            outFile = '_'.join(file_URL.split('/')[-2:])\n",
    "            outFile = os.path.join(SAVEDIR, outFile)\n",
    "        elif SOURCE == 'nomads':\n",
    "            outFile = file_URL.split('/')[-3][5:] + '_' + file_URL.split('/')[-1]\n",
    "            outFile = os.path.join(SAVEDIR, outFile)\n",
    "        \n",
    "        # Check if the URL returns a status code of 200 (meaning the URL is ok)\n",
    "        # Also check that the Content-Length is >1000000 bytes (if it's smaller,\n",
    "        # the file on the server might be incomplete)\n",
    "        head = requests.head(file_URL)\n",
    "        \n",
    "        check_exists = head.ok\n",
    "        check_content = int(head.raw.info()['Content-Length']) > 1000000\n",
    "        \n",
    "        if check_exists and check_content:\n",
    "            # Download the file\n",
    "            if searchString in [None, ':']:\n",
    "                if dryrun:\n",
    "                    print(f'üåµ Dry Run Success! Would have downloaded {file_URL} as {outFile}')\n",
    "                else:\n",
    "                    # Download the full file.\n",
    "                    urllib.request.urlretrieve(file_URL, outFile, reporthook)\n",
    "                print(f'‚úÖ Success! Downloaded {file_URL} as {outFile}')\n",
    "            else:\n",
    "                # Download a subset of the full file based on the seachString.\n",
    "                download_HRRR_subset(file_URL, searchString, \n",
    "                                     SAVEDIR=SAVEDIR, dryrun=dryrun)\n",
    "        else:\n",
    "            # The URL request is bad. If status code == 404, the URL does not exist.\n",
    "            print()\n",
    "            print(f'‚ùå WARNING: Status code {head.status_code}: {head.reason}. Content-Length: {int(head.raw.info()[\"Content-Length\"]):,} bytes')\n",
    "            print(f'‚ùå Could not download {head.url}')\n",
    "    \n",
    "    print(\"\\nFinished üç¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datetimes: DatetimeIndex(['2020-04-24 00:00:00', '2020-04-24 01:00:00',\n",
      "               '2020-04-24 02:00:00', '2020-04-24 03:00:00'],\n",
      "              dtype='datetime64[ns]', freq='H')\n",
      "Forecast Hours: [0, 3]\n"
     ]
    }
   ],
   "source": [
    "# Set the start and end date for the HRRR files we want to download\n",
    "sDATE = datetime(2020, 4, 24)\n",
    "eDATE = datetime(2020, 4, 24, 3)\n",
    "\n",
    "# Create a list of datetimes we want to download with Pandas `date_range` function.\n",
    "# The HRRR model is run every hour, so make a list of every hour\n",
    "DATES = pd.date_range(sDATE, eDATE, freq='1H')\n",
    "\n",
    "fxx = range(0, 4, 3)\n",
    "\n",
    "print('Datetimes:', DATES)\n",
    "print('Forecast Hours:', list(fxx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's call the `download_HRRR` function with our specified DATES and forecasts hours. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the full files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° Info: Downloading 8 GRIB2 files\n",
      "‚úÖ Success! Downloaded https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200424/hrrr.t00z.wrfsfcf00.grib2 as ./20200424_hrrr.t00z.wrfsfcf00.grib2\n",
      "‚úÖ Success! Downloaded https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200424/hrrr.t00z.wrfsfcf03.grib2 as ./20200424_hrrr.t00z.wrfsfcf03.grib2\n",
      "‚úÖ Success! Downloaded https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200424/hrrr.t01z.wrfsfcf00.grib2 as ./20200424_hrrr.t01z.wrfsfcf00.grib2\n",
      "‚úÖ Success! Downloaded https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200424/hrrr.t01z.wrfsfcf03.grib2 as ./20200424_hrrr.t01z.wrfsfcf03.grib2\n",
      "‚úÖ Success! Downloaded https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200424/hrrr.t02z.wrfsfcf00.grib2 as ./20200424_hrrr.t02z.wrfsfcf00.grib2\n",
      "‚úÖ Success! Downloaded https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200424/hrrr.t02z.wrfsfcf03.grib2 as ./20200424_hrrr.t02z.wrfsfcf03.grib2\n",
      "‚úÖ Success! Downloaded https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200424/hrrr.t03z.wrfsfcf00.grib2 as ./20200424_hrrr.t03z.wrfsfcf00.grib2\n",
      "‚úÖ Success! Downloaded https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200424/hrrr.t03z.wrfsfcf03.grib2 as ./20200424_hrrr.t03z.wrfsfcf03.grib2\n",
      "\n",
      "Finished üç¶\n"
     ]
    }
   ],
   "source": [
    "download_HRRR(DATES, fxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° Info: Downloading 8 GRIB2 files\n",
      "  Downloading GRIB line [ 55]: variable=UGRD, level=80 m above ground, forecast=anl\n",
      "  Downloading GRIB line [ 56]: variable=VGRD, level=80 m above ground, forecast=anl\n",
      "  Downloading GRIB line [ 71]: variable=UGRD, level=10 m above ground, forecast=anl\n",
      "  Downloading GRIB line [ 72]: variable=VGRD, level=10 m above ground, forecast=anl\n",
      "‚úÖ Success! Searched for [:(U|V)GRD:(10|80) m] and got [4] GRIB fields and saved as ./subset_20200424_hrrr.t00z.wrfsfcf00.grib2\n",
      "  Downloading GRIB line [ 55]: variable=UGRD, level=80 m above ground, forecast=3 hour fcst\n",
      "  Downloading GRIB line [ 56]: variable=VGRD, level=80 m above ground, forecast=3 hour fcst\n",
      "  Downloading GRIB line [ 71]: variable=UGRD, level=10 m above ground, forecast=3 hour fcst\n",
      "  Downloading GRIB line [ 72]: variable=VGRD, level=10 m above ground, forecast=3 hour fcst\n",
      "‚úÖ Success! Searched for [:(U|V)GRD:(10|80) m] and got [4] GRIB fields and saved as ./subset_20200424_hrrr.t00z.wrfsfcf03.grib2\n",
      "  Downloading GRIB line [ 55]: variable=UGRD, level=80 m above ground, forecast=anl\n",
      "  Downloading GRIB line [ 56]: variable=VGRD, level=80 m above ground, forecast=anl\n",
      "  Downloading GRIB line [ 71]: variable=UGRD, level=10 m above ground, forecast=anl\n",
      "  Downloading GRIB line [ 72]: variable=VGRD, level=10 m above ground, forecast=anl\n",
      "‚úÖ Success! Searched for [:(U|V)GRD:(10|80) m] and got [4] GRIB fields and saved as ./subset_20200424_hrrr.t01z.wrfsfcf00.grib2\n",
      "  Downloading GRIB line [ 55]: variable=UGRD, level=80 m above ground, forecast=3 hour fcst\n",
      "  Downloading GRIB line [ 56]: variable=VGRD, level=80 m above ground, forecast=3 hour fcst\n",
      "  Downloading GRIB line [ 71]: variable=UGRD, level=10 m above ground, forecast=3 hour fcst\n",
      "  Downloading GRIB line [ 72]: variable=VGRD, level=10 m above ground, forecast=3 hour fcst\n",
      "‚úÖ Success! Searched for [:(U|V)GRD:(10|80) m] and got [4] GRIB fields and saved as ./subset_20200424_hrrr.t01z.wrfsfcf03.grib2\n",
      "  Downloading GRIB line [ 55]: variable=UGRD, level=80 m above ground, forecast=anl\n",
      "  Downloading GRIB line [ 56]: variable=VGRD, level=80 m above ground, forecast=anl\n",
      "  Downloading GRIB line [ 71]: variable=UGRD, level=10 m above ground, forecast=anl\n",
      "  Downloading GRIB line [ 72]: variable=VGRD, level=10 m above ground, forecast=anl\n",
      "‚úÖ Success! Searched for [:(U|V)GRD:(10|80) m] and got [4] GRIB fields and saved as ./subset_20200424_hrrr.t02z.wrfsfcf00.grib2\n",
      "  Downloading GRIB line [ 55]: variable=UGRD, level=80 m above ground, forecast=3 hour fcst\n",
      "  Downloading GRIB line [ 56]: variable=VGRD, level=80 m above ground, forecast=3 hour fcst\n",
      "  Downloading GRIB line [ 71]: variable=UGRD, level=10 m above ground, forecast=3 hour fcst\n",
      "  Downloading GRIB line [ 72]: variable=VGRD, level=10 m above ground, forecast=3 hour fcst\n",
      "‚úÖ Success! Searched for [:(U|V)GRD:(10|80) m] and got [4] GRIB fields and saved as ./subset_20200424_hrrr.t02z.wrfsfcf03.grib2\n",
      "  Downloading GRIB line [ 55]: variable=UGRD, level=80 m above ground, forecast=anl\n",
      "  Downloading GRIB line [ 56]: variable=VGRD, level=80 m above ground, forecast=anl\n",
      "  Downloading GRIB line [ 71]: variable=UGRD, level=10 m above ground, forecast=anl\n",
      "  Downloading GRIB line [ 72]: variable=VGRD, level=10 m above ground, forecast=anl\n",
      "‚úÖ Success! Searched for [:(U|V)GRD:(10|80) m] and got [4] GRIB fields and saved as ./subset_20200424_hrrr.t03z.wrfsfcf00.grib2\n",
      "  Downloading GRIB line [ 55]: variable=UGRD, level=80 m above ground, forecast=3 hour fcst\n",
      "  Downloading GRIB line [ 56]: variable=VGRD, level=80 m above ground, forecast=3 hour fcst\n",
      "  Downloading GRIB line [ 71]: variable=UGRD, level=10 m above ground, forecast=3 hour fcst\n",
      "  Downloading GRIB line [ 72]: variable=VGRD, level=10 m above ground, forecast=3 hour fcst\n",
      "‚úÖ Success! Searched for [:(U|V)GRD:(10|80) m] and got [4] GRIB fields and saved as ./subset_20200424_hrrr.t03z.wrfsfcf03.grib2\n",
      "\n",
      "Finished üç¶\n"
     ]
    }
   ],
   "source": [
    "download_HRRR(DATES, fxx, ':(U|V)GRD:(10|80) m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:0:d=2020042403:UGRD:80 m above ground:3 hour fcst:\n",
      "2:1162808:d=2020042403:VGRD:80 m above ground:3 hour fcst:\n",
      "3:2358658:d=2020042403:UGRD:10 m above ground:3 hour fcst:\n",
      "4:3605847:d=2020042403:VGRD:10 m above ground:3 hour fcst:\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wgrib2 ./subset_20200424_hrrr.t03z.wrfsfcf03.grib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:0:d=2020042401:UGRD:80 m above ground:anl:\n",
      "2:1055388:d=2020042401:VGRD:80 m above ground:anl:\n",
      "3:2090097:d=2020042401:UGRD:10 m above ground:anl:\n",
      "4:3176845:d=2020042401:VGRD:10 m above ground:anl:\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wgrib2 ./subset_20200424_hrrr.t01z.wrfsfcf00.grib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:0:d=2020042401:REFC:entire atmosphere:anl:\n",
      "2:656290:d=2020042401:RETOP:cloud top:anl:\n",
      "3:1067528:d=2020042401:VIL:entire atmosphere:anl:\n",
      "4:1617824:d=2020042401:VIS:surface:anl:\n",
      "5:2900798:d=2020042401:REFD:1000 m above ground:anl:\n",
      "6:3282854:d=2020042401:REFD:4000 m above ground:anl:\n",
      "7:3596743:d=2020042401:REFD:263 K level:anl:\n",
      "8:3979400:d=2020042401:GUST:surface:anl:\n",
      "9:5147505:d=2020042401:UGRD:250 mb:anl:\n",
      "10:5870184:d=2020042401:VGRD:250 mb:anl:\n",
      "11:6531931:d=2020042401:UGRD:300 mb:anl:\n",
      "12:7275899:d=2020042401:VGRD:300 mb:anl:\n",
      "13:7964781:d=2020042401:HGT:500 mb:anl:\n",
      "14:8710191:d=2020042401:TMP:500 mb:anl:\n",
      "15:9263126:d=2020042401:DPT:500 mb:anl:\n",
      "16:10215133:d=2020042401:UGRD:500 mb:anl:\n",
      "17:10818637:d=2020042401:VGRD:500 mb:anl:\n",
      "18:11415470:d=2020042401:HGT:700 mb:anl:\n",
      "19:12165830:d=2020042401:TMP:700 mb:anl:\n",
      "20:12726609:d=2020042401:DPT:700 mb:anl:\n",
      "21:13730548:d=2020042401:UGRD:700 mb:anl:\n",
      "22:14360311:d=2020042401:VGRD:700 mb:anl:\n",
      "23:14982060:d=2020042401:HGT:850 mb:anl:\n",
      "24:15732517:d=2020042401:TMP:850 mb:anl:\n",
      "25:16314011:d=2020042401:DPT:850 mb:anl:\n",
      "26:17385936:d=2020042401:UGRD:850 mb:anl:\n",
      "27:18025855:d=2020042401:VGRD:850 mb:anl:\n",
      "28:18661863:d=2020042401:TMP:925 mb:anl:\n",
      "29:19254984:d=2020042401:DPT:925 mb:anl:\n",
      "30:20314852:d=2020042401:UGRD:925 mb:anl:\n",
      "31:20946198:d=2020042401:VGRD:925 mb:anl:\n",
      "32:21577128:d=2020042401:TMP:1000 mb:anl:\n",
      "33:22186628:d=2020042401:DPT:1000 mb:anl:\n",
      "34:23264121:d=2020042401:UGRD:1000 mb:anl:\n",
      "35:23895143:d=2020042401:VGRD:1000 mb:anl:\n",
      "36:24511874:d=2020042401:MAXUVV:100-1000 mb above ground:0-0 day max fcst:\n",
      "37:24772498:d=2020042401:MAXDVV:100-1000 mb above ground:0-0 day max fcst:\n",
      "38:25159949:d=2020042401:DZDT:0.5-0.8 sigma layer:0-0 day ave fcst:\n",
      "39:25523709:d=2020042401:MSLMA:mean sea level:anl:\n",
      "40:26145346:d=2020042401:HGT:1000 mb:anl:\n",
      "41:26839821:d=2020042401:MAXREF:1000 m above ground:0-0 day max fcst:\n",
      "42:27111492:d=2020042401:REFD:263 K level:0-0 day max fcst:\n",
      "43:27483919:d=2020042401:MXUPHL:5000-2000 m above ground:0-0 day max fcst:\n",
      "44:27484131:d=2020042401:MNUPHL:5000-2000 m above ground:0-0 day min fcst:\n",
      "45:27484343:d=2020042401:MXUPHL:2000-0 m above ground:0-0 day max fcst:\n",
      "46:27484555:d=2020042401:MNUPHL:2000-0 m above ground:0-0 day min fcst:\n",
      "47:27484767:d=2020042401:MXUPHL:3000-0 m above ground:0-0 day max fcst:\n",
      "48:27484979:d=2020042401:MNUPHL:3000-0 m above ground:0-0 day min fcst:\n",
      "49:27485191:d=2020042401:RELV:2000-0 m above ground:0-0 day max fcst:\n",
      "50:27485403:d=2020042401:RELV:1000-0 m above ground:0-0 day max fcst:\n",
      "51:27485615:d=2020042401:HAIL:entire atmosphere:0-0 day max fcst:\n",
      "52:27653250:d=2020042401:HAIL:0.1 sigma level:0-0 day max fcst:\n",
      "53:27676570:d=2020042401:TCOLG:entire atmosphere (considered as a single layer):0-0 day max fcst:\n",
      "54:27704232:d=2020042401:LTNG:entire atmosphere:anl:\n",
      "55:27704420:d=2020042401:UGRD:80 m above ground:anl:\n",
      "56:28759807:d=2020042401:VGRD:80 m above ground:anl:\n",
      "57:29794515:d=2020042401:PRES:surface:anl:\n",
      "58:31381775:d=2020042401:HGT:surface:anl:\n",
      "59:33616552:d=2020042401:TMP:surface:anl:\n",
      "60:34937333:d=2020042401:ASNOW:surface:0-0 day acc fcst:\n",
      "61:34937545:d=2020042401:MSTAV:0 m underground:anl:\n",
      "62:36282193:d=2020042401:CNWAT:surface:anl:\n",
      "63:36397147:d=2020042401:WEASD:surface:anl:\n",
      "64:36734036:d=2020042401:SNOWC:surface:anl:\n",
      "65:36870826:d=2020042401:SNOD:surface:anl:\n",
      "66:37136517:d=2020042401:TMP:2 m above ground:anl:\n",
      "67:38379116:d=2020042401:POT:2 m above ground:anl:\n",
      "68:39453253:d=2020042401:SPFH:2 m above ground:anl:\n",
      "69:40759468:d=2020042401:DPT:2 m above ground:anl:\n",
      "70:41884468:d=2020042401:RH:2 m above ground:anl:\n",
      "71:43315579:d=2020042401:UGRD:10 m above ground:anl:\n",
      "72:44402326:d=2020042401:VGRD:10 m above ground:anl:\n",
      "73:45456234:d=2020042401:WIND:10 m above ground:0-0 day max fcst:\n",
      "74:46566936:d=2020042401:MAXUW:10 m above ground:0-0 day max fcst:\n",
      "75:47653707:d=2020042401:MAXVW:10 m above ground:0-0 day max fcst:\n",
      "76:48707639:d=2020042401:CPOFP:surface:anl:\n",
      "77:48707827:d=2020042401:PRATE:surface:anl:\n",
      "78:48708015:d=2020042401:APCP:surface:0-0 day acc fcst:\n",
      "79:48708227:d=2020042401:WEASD:surface:0-0 day acc fcst:\n",
      "80:48708439:d=2020042401:FROZR:surface:0-0 day acc fcst:\n",
      "81:48708651:d=2020042401:FRZR:surface:0-0 day acc fcst:\n",
      "82:48733856:d=2020042401:SSRUN:surface:0-0 day acc fcst:\n",
      "83:48734068:d=2020042401:BGRUN:surface:0-0 day acc fcst:\n",
      "84:48734280:d=2020042401:CSNOW:surface:anl:\n",
      "85:48734468:d=2020042401:CICEP:surface:anl:\n",
      "86:48734656:d=2020042401:CFRZR:surface:anl:\n",
      "87:48734844:d=2020042401:CRAIN:surface:anl:\n",
      "88:48735032:d=2020042401:SFCR:surface:anl:\n",
      "89:50578954:d=2020042401:FRICV:surface:anl:\n",
      "90:51551193:d=2020042401:SHTFL:surface:anl:\n",
      "91:52703567:d=2020042401:LHTFL:surface:anl:\n",
      "92:53910846:d=2020042401:GFLUX:surface:anl:\n",
      "93:54480487:d=2020042401:VGTYP:surface:anl:\n",
      "94:55261312:d=2020042401:LFTX:500-1000 mb:anl:\n",
      "95:56074888:d=2020042401:CAPE:surface:anl:\n",
      "96:56541195:d=2020042401:CIN:surface:anl:\n",
      "97:56913104:d=2020042401:PWAT:entire atmosphere (considered as a single layer):anl:\n",
      "98:57805900:d=2020042401:LCDC:low cloud layer:anl:\n",
      "99:58430357:d=2020042401:MCDC:middle cloud layer:anl:\n",
      "100:58864145:d=2020042401:HCDC:high cloud layer:anl:\n",
      "101:59145889:d=2020042401:TCDC:entire atmosphere:anl:\n",
      "102:59857348:d=2020042401:PRES:cloud base:anl:\n",
      "103:60622015:d=2020042401:HGT:cloud base:anl:\n",
      "104:61820747:d=2020042401:HGT:cloud ceiling:anl:\n",
      "105:63070098:d=2020042401:PRES:cloud top:anl:\n",
      "106:63843724:d=2020042401:HGT:cloud top:anl:\n",
      "107:65090022:d=2020042401:ULWRF:top of atmosphere:anl:\n",
      "108:66920524:d=2020042401:DSWRF:surface:anl:\n",
      "109:67816532:d=2020042401:DLWRF:surface:anl:\n",
      "110:69637665:d=2020042401:USWRF:surface:anl:\n",
      "111:70303557:d=2020042401:ULWRF:surface:anl:\n",
      "112:71949520:d=2020042401:VBDSF:surface:anl:\n",
      "113:72666200:d=2020042401:VDDSF:surface:anl:\n",
      "114:73443574:d=2020042401:USWRF:top of atmosphere:anl:\n",
      "115:74245173:d=2020042401:HLCY:3000-0 m above ground:anl:\n",
      "116:75359768:d=2020042401:HLCY:1000-0 m above ground:anl:\n",
      "117:77112574:d=2020042401:USTM:0-6000 m above ground:anl:\n",
      "118:78082356:d=2020042401:VSTM:0-6000 m above ground:anl:\n",
      "119:79009828:d=2020042401:VUCSH:0-1000 m above ground:anl:\n",
      "120:80149978:d=2020042401:VVCSH:0-1000 m above ground:anl:\n",
      "121:81276988:d=2020042401:VUCSH:0-6000 m above ground:anl:\n",
      "122:82384392:d=2020042401:VVCSH:0-6000 m above ground:anl:\n",
      "123:83468235:d=2020042401:HGT:0C isotherm:anl:\n",
      "124:85317208:d=2020042401:RH:0C isotherm:anl:\n",
      "125:86062677:d=2020042401:PRES:0C isotherm:anl:\n",
      "126:86837926:d=2020042401:HGT:highest tropospheric freezing level:anl:\n",
      "127:87575477:d=2020042401:RH:highest tropospheric freezing level:anl:\n",
      "128:88304665:d=2020042401:PRES:highest tropospheric freezing level:anl:\n",
      "129:89061175:d=2020042401:HGT:263 K level:anl:\n",
      "130:89806414:d=2020042401:HGT:253 K level:anl:\n",
      "131:90483901:d=2020042401:4LFTX:180-0 mb above ground:anl:\n",
      "132:91371468:d=2020042401:CAPE:180-0 mb above ground:anl:\n",
      "133:91874874:d=2020042401:CIN:180-0 mb above ground:anl:\n",
      "134:92234741:d=2020042401:HPBL:surface:anl:\n",
      "135:95134499:d=2020042401:HGT:level of adiabatic condensation from sfc:anl:\n",
      "136:97830680:d=2020042401:CAPE:90-0 mb above ground:anl:\n",
      "137:98215463:d=2020042401:CIN:90-0 mb above ground:anl:\n",
      "138:98535808:d=2020042401:CAPE:255-0 mb above ground:anl:\n",
      "139:99092818:d=2020042401:CIN:255-0 mb above ground:anl:\n",
      "140:99474216:d=2020042401:HGT:equilibrium level:anl:\n",
      "141:101692268:d=2020042401:PLPL:255-0 mb above ground:anl:\n",
      "142:102897626:d=2020042401:RHPW:entire atmosphere:anl:\n",
      "143:104092638:d=2020042401:LAND:surface:anl:\n",
      "144:104143114:d=2020042401:ICEC:surface:anl:\n",
      "145:104156805:d=2020042401:SBT123:top of atmosphere:anl:\n",
      "146:105885801:d=2020042401:SBT124:top of atmosphere:anl:\n",
      "147:107657611:d=2020042401:SBT113:top of atmosphere:anl:\n",
      "148:109240237:d=2020042401:SBT114:top of atmosphere:anl:\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wgrib2 ./20200424_hrrr.t01z.wrfsfcf00.grib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåµ Info: Dry Run 8 GRIB2 files\n",
      "    üê´ Dry Run: Found GRIB line [  9]: variable=UGRD, level=250 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 10]: variable=VGRD, level=250 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 11]: variable=UGRD, level=300 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 12]: variable=VGRD, level=300 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 16]: variable=UGRD, level=500 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 17]: variable=VGRD, level=500 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 21]: variable=UGRD, level=700 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 22]: variable=VGRD, level=700 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 26]: variable=UGRD, level=850 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 27]: variable=VGRD, level=850 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 30]: variable=UGRD, level=925 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 31]: variable=VGRD, level=925 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 34]: variable=UGRD, level=1000 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 35]: variable=VGRD, level=1000 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 55]: variable=UGRD, level=80 m above ground, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 56]: variable=VGRD, level=80 m above ground, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 71]: variable=UGRD, level=10 m above ground, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 72]: variable=VGRD, level=10 m above ground, forecast=anl\n",
      "üåµ Dry Run: Success! Searched for [:(U|V)GRD:] and found [18] GRIB fields. Would save as ./subset_20200424_hrrr.t00z.wrfsfcf00.grib2\n",
      "    üê´ Dry Run: Found GRIB line [  9]: variable=UGRD, level=250 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 10]: variable=VGRD, level=250 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 11]: variable=UGRD, level=300 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 12]: variable=VGRD, level=300 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 16]: variable=UGRD, level=500 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 17]: variable=VGRD, level=500 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 21]: variable=UGRD, level=700 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 22]: variable=VGRD, level=700 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 26]: variable=UGRD, level=850 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 27]: variable=VGRD, level=850 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 30]: variable=UGRD, level=925 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 31]: variable=VGRD, level=925 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 34]: variable=UGRD, level=1000 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 35]: variable=VGRD, level=1000 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 55]: variable=UGRD, level=80 m above ground, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 56]: variable=VGRD, level=80 m above ground, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 71]: variable=UGRD, level=10 m above ground, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 72]: variable=VGRD, level=10 m above ground, forecast=3 hour fcst\n",
      "üåµ Dry Run: Success! Searched for [:(U|V)GRD:] and found [18] GRIB fields. Would save as ./subset_20200424_hrrr.t00z.wrfsfcf03.grib2\n",
      "    üê´ Dry Run: Found GRIB line [  9]: variable=UGRD, level=250 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 10]: variable=VGRD, level=250 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 11]: variable=UGRD, level=300 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 12]: variable=VGRD, level=300 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 16]: variable=UGRD, level=500 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 17]: variable=VGRD, level=500 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 21]: variable=UGRD, level=700 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 22]: variable=VGRD, level=700 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 26]: variable=UGRD, level=850 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 27]: variable=VGRD, level=850 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 30]: variable=UGRD, level=925 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 31]: variable=VGRD, level=925 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 34]: variable=UGRD, level=1000 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 35]: variable=VGRD, level=1000 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 55]: variable=UGRD, level=80 m above ground, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 56]: variable=VGRD, level=80 m above ground, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 71]: variable=UGRD, level=10 m above ground, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 72]: variable=VGRD, level=10 m above ground, forecast=anl\n",
      "üåµ Dry Run: Success! Searched for [:(U|V)GRD:] and found [18] GRIB fields. Would save as ./subset_20200424_hrrr.t01z.wrfsfcf00.grib2\n",
      "    üê´ Dry Run: Found GRIB line [  9]: variable=UGRD, level=250 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 10]: variable=VGRD, level=250 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 11]: variable=UGRD, level=300 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 12]: variable=VGRD, level=300 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 16]: variable=UGRD, level=500 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 17]: variable=VGRD, level=500 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 21]: variable=UGRD, level=700 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 22]: variable=VGRD, level=700 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 26]: variable=UGRD, level=850 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 27]: variable=VGRD, level=850 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 30]: variable=UGRD, level=925 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 31]: variable=VGRD, level=925 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 34]: variable=UGRD, level=1000 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 35]: variable=VGRD, level=1000 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 55]: variable=UGRD, level=80 m above ground, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 56]: variable=VGRD, level=80 m above ground, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 71]: variable=UGRD, level=10 m above ground, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 72]: variable=VGRD, level=10 m above ground, forecast=3 hour fcst\n",
      "üåµ Dry Run: Success! Searched for [:(U|V)GRD:] and found [18] GRIB fields. Would save as ./subset_20200424_hrrr.t01z.wrfsfcf03.grib2\n",
      "    üê´ Dry Run: Found GRIB line [  9]: variable=UGRD, level=250 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 10]: variable=VGRD, level=250 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 11]: variable=UGRD, level=300 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 12]: variable=VGRD, level=300 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 16]: variable=UGRD, level=500 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 17]: variable=VGRD, level=500 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 21]: variable=UGRD, level=700 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 22]: variable=VGRD, level=700 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 26]: variable=UGRD, level=850 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 27]: variable=VGRD, level=850 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 30]: variable=UGRD, level=925 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 31]: variable=VGRD, level=925 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 34]: variable=UGRD, level=1000 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 35]: variable=VGRD, level=1000 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 55]: variable=UGRD, level=80 m above ground, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 56]: variable=VGRD, level=80 m above ground, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 71]: variable=UGRD, level=10 m above ground, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 72]: variable=VGRD, level=10 m above ground, forecast=anl\n",
      "üåµ Dry Run: Success! Searched for [:(U|V)GRD:] and found [18] GRIB fields. Would save as ./subset_20200424_hrrr.t02z.wrfsfcf00.grib2\n",
      "    üê´ Dry Run: Found GRIB line [  9]: variable=UGRD, level=250 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 10]: variable=VGRD, level=250 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 11]: variable=UGRD, level=300 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 12]: variable=VGRD, level=300 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 16]: variable=UGRD, level=500 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 17]: variable=VGRD, level=500 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 21]: variable=UGRD, level=700 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 22]: variable=VGRD, level=700 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 26]: variable=UGRD, level=850 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 27]: variable=VGRD, level=850 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 30]: variable=UGRD, level=925 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 31]: variable=VGRD, level=925 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 34]: variable=UGRD, level=1000 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 35]: variable=VGRD, level=1000 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 55]: variable=UGRD, level=80 m above ground, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 56]: variable=VGRD, level=80 m above ground, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 71]: variable=UGRD, level=10 m above ground, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 72]: variable=VGRD, level=10 m above ground, forecast=3 hour fcst\n",
      "üåµ Dry Run: Success! Searched for [:(U|V)GRD:] and found [18] GRIB fields. Would save as ./subset_20200424_hrrr.t02z.wrfsfcf03.grib2\n",
      "    üê´ Dry Run: Found GRIB line [  9]: variable=UGRD, level=250 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 10]: variable=VGRD, level=250 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 11]: variable=UGRD, level=300 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 12]: variable=VGRD, level=300 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 16]: variable=UGRD, level=500 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 17]: variable=VGRD, level=500 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 21]: variable=UGRD, level=700 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 22]: variable=VGRD, level=700 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 26]: variable=UGRD, level=850 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 27]: variable=VGRD, level=850 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 30]: variable=UGRD, level=925 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 31]: variable=VGRD, level=925 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 34]: variable=UGRD, level=1000 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 35]: variable=VGRD, level=1000 mb, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 55]: variable=UGRD, level=80 m above ground, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 56]: variable=VGRD, level=80 m above ground, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 71]: variable=UGRD, level=10 m above ground, forecast=anl\n",
      "    üê´ Dry Run: Found GRIB line [ 72]: variable=VGRD, level=10 m above ground, forecast=anl\n",
      "üåµ Dry Run: Success! Searched for [:(U|V)GRD:] and found [18] GRIB fields. Would save as ./subset_20200424_hrrr.t03z.wrfsfcf00.grib2\n",
      "    üê´ Dry Run: Found GRIB line [  9]: variable=UGRD, level=250 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 10]: variable=VGRD, level=250 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 11]: variable=UGRD, level=300 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 12]: variable=VGRD, level=300 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 16]: variable=UGRD, level=500 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 17]: variable=VGRD, level=500 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 21]: variable=UGRD, level=700 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 22]: variable=VGRD, level=700 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 26]: variable=UGRD, level=850 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 27]: variable=VGRD, level=850 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 30]: variable=UGRD, level=925 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 31]: variable=VGRD, level=925 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 34]: variable=UGRD, level=1000 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 35]: variable=VGRD, level=1000 mb, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 55]: variable=UGRD, level=80 m above ground, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 56]: variable=VGRD, level=80 m above ground, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 71]: variable=UGRD, level=10 m above ground, forecast=3 hour fcst\n",
      "    üê´ Dry Run: Found GRIB line [ 72]: variable=VGRD, level=10 m above ground, forecast=3 hour fcst\n",
      "üåµ Dry Run: Success! Searched for [:(U|V)GRD:] and found [18] GRIB fields. Would save as ./subset_20200424_hrrr.t03z.wrfsfcf03.grib2\n",
      "\n",
      "Finished üç¶\n"
     ]
    }
   ],
   "source": [
    "download_HRRR(DATES, fxx, ':(U|V)GRD:', dryrun=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
